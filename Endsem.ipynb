{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ff9059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88400f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(trainfile='MNIST_train.csv', validationfile='MNIST_validation.csv'):\n",
    "    \n",
    "    dftrain = pd.read_csv(trainfile)\n",
    "    dfval = pd.read_csv(validationfile)\n",
    "\n",
    "    featurecols = list(dftrain.columns)\n",
    "    featurecols.remove('label')\n",
    "    featurecols.remove('even')\n",
    "    targetcol = 'label'\n",
    "\n",
    "    Xtrain = dftrain[featurecols]\n",
    "    ytrain = dftrain[targetcol]\n",
    "    \n",
    "    Xval = dfval[featurecols]\n",
    "    yval = dfval[targetcol]\n",
    "\n",
    "    return (Xtrain, ytrain, Xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3862a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiclass XGB by making some changes to our XGB for binary classification\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feat=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feat = feat\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "class XGBoostClassifier:\n",
    "    def __init__(self, n_estimators=10, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        self.init_score = 0.0\n",
    "        self.proba_threshold = 0.0\n",
    "\n",
    "    #Softmax\n",
    "    def _softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "    #to one hot\n",
    "    def _to_one_hot(self, y):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        one_hot = np.zeros((y.shape[0], self.n_classes))\n",
    "        one_hot[np.arange(y.shape[0]), y] = 1\n",
    "        return one_hot\n",
    "\n",
    "    #build tree function\n",
    "    def _build_tree(self, X, grad, hess, depth):\n",
    "        #terminal condition\n",
    "        if depth >= self.max_depth or X.shape[0] <= 1:\n",
    "            leaf_value = -np.sum(grad) / (np.sum(hess) + 1e-8)\n",
    "            return Node(value=leaf_value)\n",
    "        #finding best split\n",
    "        best_gain = -float('inf')\n",
    "        best_feat = None\n",
    "        best_thresh = None\n",
    "        best_left = None\n",
    "        best_right = None\n",
    "        G_total, H_total = np.sum(grad), np.sum(hess)\n",
    "        for j in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, j])\n",
    "            for threshold in thresholds:\n",
    "                left = X[:, j] <= threshold\n",
    "                right = ~left\n",
    "                if np.any(left) and np.any(right):\n",
    "                    G_l, H_l = np.sum(grad[left]), np.sum(hess[left])\n",
    "                    G_r, H_r = np.sum(grad[right]), np.sum(hess[right])\n",
    "                    gain = 0.5 * (\n",
    "                        G_l**2/(H_l+1e-8) +\n",
    "                        G_r**2/(H_r+1e-8) -\n",
    "                        G_total**2/(H_total+1e-8)\n",
    "                    )\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_feat = j\n",
    "                        best_thresh = threshold\n",
    "                        best_left, best_right = left, right\n",
    "        #if no split is possible\n",
    "        if best_gain == -float('inf'):\n",
    "            leaf_value = -np.sum(grad) / (np.sum(hess) + 1e-8)\n",
    "            return Node(value=leaf_value)\n",
    "        #recursion step\n",
    "        left_node = self._build_tree(X[best_left], grad[best_left], hess[best_left], depth+1)\n",
    "        right_node = self._build_tree(X[best_right], grad[best_right], hess[best_right], depth+1)\n",
    "        return Node(feat=best_feat, threshold=best_thresh, left=left_node, right=right_node)\n",
    "\n",
    "    #prediction for a single row\n",
    "    def _predict_row(self, x, node):\n",
    "        while node.value is None:\n",
    "            if x[node.feat] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.value\n",
    "\n",
    "    #fit function\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        y_one_hot = self._to_one_hot(y)\n",
    "        \n",
    "        pred = np.zeros((X.shape[0], self.n_classes), dtype=float)\n",
    "        \n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            prob = self._softmax(pred)\n",
    "            \n",
    "            grad = prob - y_one_hot\n",
    "            hess = prob * (1 - prob)\n",
    "            \n",
    "            round_trees = []\n",
    "            \n",
    "            # Build one tree for each class\n",
    "            for k in range(self.n_classes):\n",
    "                grad_k = grad[:, k]\n",
    "                hess_k = hess[:, k]\n",
    "                tree = self._build_tree(X, grad_k, hess_k, depth=0)\n",
    "                round_trees.append(tree)\n",
    "                update = np.array([self._predict_row(row, tree) for row in X])\n",
    "                pred[:, k] += self.learning_rate * update\n",
    "            self.trees.append(round_trees)\n",
    "\n",
    "    #predict probability for each class\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X)\n",
    "        pred = np.zeros((X.shape[0], self.n_classes), dtype=float)\n",
    "        \n",
    "        for tree_group in self.trees:\n",
    "            for k in range(self.n_classes):\n",
    "                tree_k = tree_group[k]\n",
    "                update = np.array([self._predict_row(row, tree_k) for row in X])\n",
    "                pred[:, k] += self.learning_rate * update\n",
    "        return self._softmax(pred)\n",
    "\n",
    "    #Predicting the class with highest probability\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.argmax(proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f5c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "class PCAModel:\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.mean = None\n",
    "        self.components = None\n",
    "        self.explained_variance = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = np.array(X, dtype=float)\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        X_centered = X - self.mean\n",
    "        cov_matrix = np.cov(X_centered, rowvar=False)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "        sorted_idx = np.argsort(eigenvalues)[::-1]\n",
    "        self.explained_variance = eigenvalues[sorted_idx][:self.n_components]\n",
    "        self.components = eigenvectors[:, sorted_idx][:, :self.n_components]\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.mean is None or self.components is None:\n",
    "            raise ValueError(\"The PCA model has not been fitted yet.\")\n",
    "\n",
    "        X_centered = X - self.mean\n",
    "        \n",
    "        return np.dot(X_centered, self.components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "baac01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with PCA\n",
    "class KNeighborsClassifier:\n",
    "    \n",
    "    def __init__(self, k=5, dims = 100):\n",
    "        # dims = no. of reduced dimensions for PCA,\n",
    "        # k = no. of nearest neighbours.\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.n_classes = 0\n",
    "        self.dims = dims\n",
    "        self.pca = PCAModel(n_components=self.dims)\n",
    "\n",
    "    #Recording the training points\n",
    "    def fit(self, X, y):\n",
    "        self.pca.fit(X)\n",
    "        X = self.pca.predict(X)\n",
    "        self.X_train = np.asarray(X)\n",
    "        self.y_train = np.asarray(y)\n",
    "        self.n_classes = len(np.unique(self.y_train))\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(self.pca.predict(X))\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        #Distance calculation\n",
    "        x_sq = np.sum(X**2, axis=1, keepdims=True)\n",
    "        train_sq = np.sum(self.X_train.T**2, axis=0, keepdims=True)\n",
    "        two_ab = -2 * np.dot(X, self.X_train.T)\n",
    "        dists_sq = x_sq + two_ab + train_sq\n",
    "        \n",
    "        #Assigning probability to each class based on K nearest neighbours\n",
    "        k_nearest_indices = np.argsort(dists_sq, axis=1)[:, :self.k]\n",
    "        k_nearest_labels = self.y_train[k_nearest_indices]\n",
    "        probabilities = np.zeros((n_samples, self.n_classes), dtype=float)\n",
    "        for c in range(self.n_classes):\n",
    "            probabilities[:, c] = np.sum(k_nearest_labels == c, axis=1)\n",
    "        probabilities = probabilities / self.k\n",
    "                \n",
    "        return probabilities\n",
    "\n",
    "    #Returning class with the greatst probability\n",
    "    def predict(self, X):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2a8483ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,ytrain,Xval,yval = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "df99b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(k=1, dims = 100)\n",
    "knn.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "27174e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555822328931572\n"
     ]
    }
   ],
   "source": [
    "ypred = knn.predict(Xval)\n",
    "print(accuracy_score(ypred,yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "95591e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One vs All accuracy scores\n",
    "def calculate_scores(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    overall_accuracy = np.mean(y_true == y_pred)\n",
    "    unique_labels = np.unique(y_true)\n",
    "    \n",
    "    metrics = {\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'class_metrics': {}\n",
    "    }\n",
    "    for class_label in unique_labels:\n",
    "        is_class_true = (y_true == class_label)\n",
    "        is_class_pred = (y_pred == class_label)\n",
    "        \n",
    "        TP = np.sum(is_class_true & is_class_pred)\n",
    "        TN = np.sum(~is_class_true & ~is_class_pred)\n",
    "        FP = np.sum(~is_class_true & is_class_pred)\n",
    "        FN = np.sum(is_class_true & ~is_class_pred)\n",
    "        \n",
    "        total_negatives = TN + FP\n",
    "        total_samples = len(y_true)\n",
    "\n",
    "        fpr = FP / total_negatives if total_negatives > 0 else 0.0\n",
    "        fnr = FN / total_negatives if total_negatives > 0 else 0.0\n",
    "        acc = (TP + TN) / total_samples if total_samples > 0 else 0.0\n",
    "        \n",
    "        metrics['class_metrics'][str(class_label)] = {\n",
    "            'accuracy': acc,\n",
    "            'fpr': fpr,\n",
    "            'fnr': fnr,\n",
    "        }\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1d08607f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overall_accuracy': np.float64(0.9555822328931572), 'class_metrics': {'0': {'accuracy': np.float64(0.9967987194877951), 'fpr': np.float64(0.0026642984014209592), 'fnr': np.float64(0.0008880994671403197)}, '1': {'accuracy': np.float64(0.9951980792316927), 'fpr': np.float64(0.004508566275924256), 'fnr': np.float64(0.0009017132551848512)}, '2': {'accuracy': np.float64(0.992797118847539), 'fpr': np.float64(0.003109729009329187), 'fnr': np.float64(0.004886717014660151)}, '3': {'accuracy': np.float64(0.9903961584633854), 'fpr': np.float64(0.004010695187165776), 'fnr': np.float64(0.0066844919786096255)}, '4': {'accuracy': np.float64(0.9903961584633854), 'fpr': np.float64(0.0062056737588652485), 'fnr': np.float64(0.004432624113475178)}, '5': {'accuracy': np.float64(0.988795518207283), 'fpr': np.float64(0.007039155301363837), 'fnr': np.float64(0.005279366476022877)}, '6': {'accuracy': np.float64(0.9935974389755903), 'fpr': np.float64(0.0039946737683089215), 'fnr': np.float64(0.0031069684864624943)}, '7': {'accuracy': np.float64(0.9903961584633854), 'fpr': np.float64(0.008489722966934763), 'fnr': np.float64(0.002234137622877569)}, '8': {'accuracy': np.float64(0.9871948779511804), 'fpr': np.float64(0.0022172949002217295), 'fnr': np.float64(0.01197339246119734)}, '9': {'accuracy': np.float64(0.985594237695078), 'fpr': np.float64(0.007107952021323856), 'fnr': np.float64(0.00888494002665482)}}}\n"
     ]
    }
   ],
   "source": [
    "print(calculate_scores(yval, ypred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
